







@article{
doi:10.1126/science.abn0915,
author = {B. Thompson  and B. van Opheusden  and T. Sumers  and T. L. Griffiths },
title = {Complex cognitive algorithms preserved by selective social learning in experimental populations},
journal = {Science},
volume = {376},
number = {6588},
pages = {95-98},
year = {2022},
doi = {10.1126/science.abn0915},
URL = {https://www.science.org/doi/abs/10.1126/science.abn0915},
eprint = {https://www.science.org/doi/pdf/10.1126/science.abn0915},
abstract = {Many human abilities rely on cognitive algorithms discovered by previous generations. Cultural accumulation of innovative algorithms is hard to explain because complex concepts are difficult to pass on. We found that selective social learning preserved rare discoveries of exceptional algorithms in a large experimental simulation of cultural evolution. Participants (N = 3450) faced a difficult sequential decision problem (sorting an unknown sequence of numbers) and transmitted solutions across 12 generations in 20 populations. Several known sorting algorithms were discovered. Complex algorithms persisted when participants could choose who to learn from but frequently became extinct in populations lacking this selection process, converging on highly transmissible lower-performance algorithms. These results provide experimental evidence for hypothesized links between sociality and cognitive function in humans. Our capacity to accumulate complex algorithms over generations allows human beings to adapt to diverse environments and solve challenges that go beyond our individual limitations. However, cultural accumulation of innovative algorithms is difficult to explain. Thompson et al. studied a large number of participants to explore the evolution of algorithms under different learning conditions (see the Perspective by Henrich). Selective social learning that involved knowledge of the success level of different strategies or of different models preserved difficult-to-invent, efficient algorithms more than random social learning or one-attempt asocial learning. Two efficient algorithms were used by many people, but the most efficient one only spread under selective social learning. â€”PRS An experimental simulation of cultural evolution shows that selecting who to learn from is key to maintaining complex discoveries.}}

